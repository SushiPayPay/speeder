exp_name: test
run_name: test

global_batch_size: 16384
epochs: 1
train_workers: 1
cpus_per_train_worker: 1
gpus_per_train_worker: 1

gpu_ids: -1

lr: tune.uniform(0,1)

# 2 min 52 sec total w/ 8 gpus